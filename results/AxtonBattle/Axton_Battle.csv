Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Environment/Episode Length,Self-play/ELO,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
2000,51847024.0,4.60668e-05,3764774000000000.0,0.14313328,0.0003,0.29999995,0.0049999994,896.0,1199.75,-4691.100006103516,-4691.100006103516,1.0
3000,41774224.0,4.6066798e-05,2484474800000000.0,0.13703561,0.0003,0.29999995,0.0049999994,1200.0,1199.0014391117093,-5709.200019836426,-5709.200019836426,1.0
4000,41171430.0,4.606531e-05,1240289400000000.0,0.13052937,0.00029999999,0.29999998,0.0049999994,556.0,1199.0043131693246,-3014.999954223633,-3014.999954223633,1.0
5000,40318190.0,4.606798e-05,631779600000000.0,0.13883954,0.0003,0.29999995,0.0049999994,1200.0,1199.5071789550097,-1923.8000316619873,-1923.8000316619873,1.0
6000,36132016.0,4.6067664e-05,392864850000000.0,0.12972474,0.0003,0.29999995,0.0049999994,277.0,1199.0085974041942,-2565.9000701904297,-2565.9000701904297,1.0
7000,34596390.0,4.6066954e-05,129385320000000.0,0.14025694,0.00029999999,0.29999998,0.0049999994,719.0,1198.513593001249,-4057.599956512451,-4057.599956512451,1.0
8000,29795000.0,4.60674e-05,124712770000000.0,0.14813,0.00030000007,0.29999995,0.0049999994,693.5,1197.7728564124047,-4438.700023651123,-4438.700023651123,1.0
9000,24752128.0,4.6069297e-05,164617440000000.0,0.13970628,0.0003,0.29999995,0.0049999994,None,None,None,None,1.0
10000,25781172.0,4.606732e-05,108174200000000.0,0.12909806,0.00029999999,0.29999998,0.0049999994,717.0,1197.5363771465945,-5246.199971199036,-5246.199971199036,1.0
